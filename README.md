# Multi-Agent AI System ğŸ¤–

A multi-agent AI system that can handle different types of documents (PDFs, JSON files, and emails) and process them intelligently. It figures out what type of document you're dealing with and sends it to the right agent for processing.

## What it does ğŸ“‹

This system takes your documents and:
- ğŸ“„ Classifies PDFs (like invoices, contracts, reports)
- ğŸ” Validates and processes JSON data
- ğŸ“§ Analyzes emails for intent and urgency
- ğŸ§  Keeps track of everything in a shared memory so all agents can work together

## How it works âš™ï¸

The system has three main agents:

**Classifier Agent** ğŸ“Š - Takes PDF documents and figures out what they are (invoice, contract, etc.)

**JSON Agent** ğŸ”§ - Handles JSON files, validates them, and extracts important data

**Email Agent** ğŸ“® - Reads emails and determines what the sender wants and how urgent it is

All agents share information through a memory system so they can work together on complex tasks.

## What you need ğŸ“‹

- Python 3.8 or newer ğŸ
- At least 4GB of RAM (for running the AI model) ğŸ’¾
- Ollama installed on your computer ğŸ› ï¸

## Setup ğŸš€

### 1. Install Ollama ğŸ“¥

Go to https://ollama.com/download and install Ollama for your operating system.

After installing, run these commands:

```bash
ollama pull mistral
ollama serve
```

The server will run in the background.

### 2. Get the code ğŸ“‚

```bash
git clone https://github.com/Prabhatcodes-x/Multi-Agent-AI-System.git
cd Multi-Agent-AI-System
pip install -r requirements.txt
```

### 3. Run it â–¶ï¸

```bash
python main.py
```

## What happens when you run it âœ¨

The system will:
1. Process the sample files in the `sample_inputs` folder ğŸ“
2. Show you what it's doing in the terminal ğŸ’»
3. Save detailed logs to `output_logs/agent_activity.log` ğŸ“
4. Keep track of all processed documents in `output_logs/shared_memory.json` ğŸ—„ï¸

## Project structure ğŸ“

```
multi_agent_system/
â”œâ”€â”€ agents/                 # The three main agents
â”‚   â”œâ”€â”€ classifier_agent.py
â”‚   â”œâ”€â”€ email_agent.py
â”‚   â””â”€â”€ json_agent.py
â”œâ”€â”€ memory/                 # Shared memory system
â”‚   â””â”€â”€ shared_memory.py
â”œâ”€â”€ output_logs/           # Logs and results (created when you run it)
â”œâ”€â”€ sample_inputs/         # Test files to try it out
â”œâ”€â”€ utils/                 # Helper functions
â”œâ”€â”€ main.py               # Main file to run
â””â”€â”€ requirements.txt      # Python packages needed
```

## Adding your own files ğŸ“„

Put your files in the `sample_inputs` folder:
- PDFs: Any PDF document you want classified ğŸ“„
- JSON files: Structured data you want validated ğŸ”§
- Text files: Email content you want analyzed ğŸ“§

The system will automatically detect what type of file it is and process it accordingly.

## If something goes wrong ğŸš¨

**"Connection refused" error**: Make sure Ollama is running with `ollama serve` âš ï¸

**"Model not found"**: Download the model with `ollama pull mistral` ğŸ“¥

**Permission errors**: Make sure the `output_logs` folder can be written to ğŸ“

**Import errors**: Reinstall requirements with `pip install -r requirements.txt` ğŸ”„

## How to customize it ğŸ› ï¸

You can modify the agents to handle different types of documents or add new processing logic. Each agent is in its own file in the `agents` folder.

The system uses the Mistral AI model through Ollama, but you can change this in the configuration if you want to use a different model.

## What makes it useful â­

- **Works offline**: Everything runs on your computer, no data sent to external servers ğŸ”’
- **Handles multiple formats**: PDFs, JSON, and emails all in one system ğŸ“š
- **Smart fallbacks**: If the AI model fails, it falls back to rule-based processing ğŸ§ 
- **Keeps context**: All agents share information so they can work together ğŸ¤
- **Easy to extend**: Add new agents or modify existing ones ğŸ”§

## Performance âš¡

- PDF processing: Usually takes 2-5 seconds per document ğŸ“„
- JSON validation: Very fast, under 1 second âš¡
- Email analysis: 1-3 seconds per email ğŸ“§
- Memory usage: About 1-2GB when running (mostly for the AI model) ğŸ’¾

## Contributing ğŸ¤

If you want to improve this project:
1. Fork the repository ğŸ´
2. Make your changes âœï¸
3. Test them with the sample files ğŸ§ª
4. Submit a pull request ğŸ“¤

Try to keep the code simple and well-commented so others can understand it.

## License ğŸ“„

MIT License - you can use this code for whatever you want. ğŸ‰

## Credits ğŸ™

Built using:
- Ollama for running AI models locally ğŸ¤–
- Mistral AI for the language model ğŸ§ 
- pdfplumber for reading PDF files ğŸ“„
- Standard Python libraries for everything else ğŸ
